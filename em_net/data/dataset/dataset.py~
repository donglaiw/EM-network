from __future__ import print_function, division
import numpy as np
import random

import torch
import torch.utils.data

# use image augmentation
from ..augmentation import IntensityAugment, simpleaug_train_produce
from ..augmentation import apply_elastic_transform, apply_deform

#from em_dataLib.augmentation.augmentor import build_augmentor
#from em_dataLib.sampling.sampler import build_sampler


# -- 1.0 dataset -- 
# dataset class for synaptic cleft inputs
class BaseDataset(torch.utils.data.Dataset):
    # assume for test, no warping [hassle to warp it back..]
    # sample_input_size: sample input size
    # sample_input_size: sample input size
    def __init__(self,
                 volume, label=None,
                 sample_input_size=(8, 64, 64),
                 sample_label_size=None,
                 sample_stride=(1, 1, 1),
                 augmentor=None,
                 label_invalid = None,
                 mode='train'):

        self.mode = mode

        # data format
        self.input = volume
        self.label = label
        self.label_invalid = label_mask
        self.augmentor = augmentor  # data augmentation

        # samples, channels, depths, rows, cols
        self.input_size = [np.array(x.shape) for x in self.input]  # volume size, could be multi-volume input
        self.sample_input_size = np.array(sample_input_size)  # model input size
        self.sample_label_size = np.array(sample_label_size)  # model label size

        # compute number of samples for each dataset (multi-volume input)
        self.sample_stride = np.array(sample_stride, dtype=np.float32)
        self.sample_size = [count_volume(self.input_size[x], self.sample_input_size, np.array(self.sample_stride))
                            for x in range(len(self.input_size))]
        # total number of possible inputs for each volume
        self.sample_num = np.array([np.prod(x) for x in self.sample_size])
        # check partial label
        if label is not None and label_par:

        self.sample_num_a = np.sum(self.sample_num)
        self.sample_num_c = np.cumsum([0] + list(self.sample_num))
        # print(self.sample_num_c)
        assert self.sample_num_c[-1] == self.sample_num_a

        '''
        Image augmentation
        1. self.simple_aug: Simple augmentation, including mirroring and transpose
        2. self.intensity_aug: Intensity augmentation
        '''
        if self.augmentor is not None:
            self.simple_aug = simpleaug_train_produce(model_io_size=self.sample_input_size)
            self.intensity_aug = IntensityAugment(mode='mix', skip_ratio=0.5, CONTRAST_FACTOR=0.1,
                                                  BRIGHTNESS_FACTOR=0.1)
        if mode=='test': # for test
            self.sample_size_vol = [np.array([np.prod(x[1:3]), x[2]]) for x in self.sample_size]

    def __getitem__(self, index):
        raise NotImplementedError("Need to implement getitem() !")

    def __len__(self):  # number of possible position
        return self.sample_num_a

    def get_pos_dataset(self, index):
        return np.argmax(index < self.sample_num_c) - 1  # which dataset

    def get_pos(self, vol_size, index):
        pos = [0, 0, 0, 0]
        # support random sampling using the same 'index'
        seed = np.random.RandomState(index)
        did = self.get_pos_dataset(seed.randint(self.sample_num_a))
        pos[0] = did
        tmp_size = count_volume(self.input_size[did], vol_size, np.array(self.sample_stride))
        pos[1:] = [np.random.randint(tmp_size[x]) for x in range(len(tmp_size))]
        return pos

    def index2zyx(self, index):  # for test
        # int division = int(floor(.))
        pos = [0,0,0,0]
        did = self.get_pos_dataset(index)
        pos[0] = did
        index2 = index - self.sample_num_c[did]
        pos[1:] = self.get_pos_location(index2, self.sample_size_vol[did])
        return pos

    def get_pos_location(self, index, sz):
        # index -> z,y,x
        # sz: [y*x, x]
        pos = [0, 0, 0]
        pos[0] = np.floor(index/sz[0])
        pz_r = index % sz[0]
        pos[1] = np.floor(pz_r/sz[1])
        pos[2] = pz_r % sz[1]
        return pos

    def get_pos_test(self, index):
        pos = self.index2zyx(index)
        for i in range(1, 4):
            if pos[i] != self.sample_size[pos[0]][i-1]-1:
                pos[i] = int(pos[i] * self.sample_stride[i-1])
            else:
                pos[i] = int(self.input_size[pos[0]][i-1]-self.sample_input_size[i-1])
        return pos

    def get_pos_seed(self, vol_size, seed):
        pos = [0, 0, 0, 0]
        # pick a dataset
        did = self.get_pos_dataset(seed.randint(self.sample_num_a))
        pos[0] = did
        # pick a position
        tmp_size = count_volume(self.input_size[did], vol_size, np.array(self.sample_stride))
        pos[1:] = [np.random.randint(tmp_size[x]) for x in range(len(tmp_size))]
        return pos


# -- 2. misc --
# for dataloader

def collate_fn(batch):
    """
    Puts each data field into a tensor with outer dimension batch size
    :param batch:
    :return:
    """
    pos, out_input, out_label, weights, weight_factor = zip(*batch)
    out_input = torch.stack(out_input, 0)
    out_label = torch.stack(out_label, 0)
    weights = torch.stack(weights, 0)
    weight_factor = np.stack(weight_factor, 0)
    return pos, out_input, out_label, weights, weight_factor

def collate_fn_test(batch):
    pos, out_input, out_label, weights, weight_factor = zip(*batch)
    out_input = torch.stack(out_input, 0)
    return pos, out_input, out_label, weights, weight_factor

def count_volume(data_sz, vol_sz, stride):
    return 1 + np.ceil((data_sz - vol_sz) / stride.astype(float)).astype(int)

def crop_volume(data, sz, st=(0, 0, 0)):  # C*D*W*H, C=1
    return data[st[0]:st[0]+sz[0], st[1]:st[1]+sz[1], st[2]:st[2]+sz[2]]

def crop_volume_mul(data, sz, st=(0, 0, 0)):  # C*D*W*H, for multi-channel input
    return data[:, st[0]:st[0]+sz[0], st[1]:st[1]+sz[1], st[2]:st[2]+sz[2]]
